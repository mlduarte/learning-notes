---
title: Linear Algebra Recap
author: ''
date: '2018-06-20T13:39:46+02:00'
slug: linear-algebra-recap
banner: "img/banners/linear_algebra.png"
categories:
  - Study-Notes
tags:   
  - Study-Notes
---



<div id="eigenvalues-eigenvector-diagonalisation-recap-elementary-linear-algebra-anton" class="section level1">
<h1>Eigenvalues, Eigenvector, diagonalisation Recap (Elementary Linear Algebra, Anton)</h1>
<p>Eigenvalues consolidate the variance within a matrix, while providing the linear combatination of variables (eigenvector) to do it.</p>
<p>If <span class="math inline">\(A\)</span> is an <span class="math inline">\(n \text{x} n\)</span> matrix, then vector <span class="math inline">\(\mathbf{x}\)</span> in <span class="math inline">\(R^n\)</span> is an eigenvector of <span class="math inline">\(A\)</span> if <span class="math inline">\(A\mathbf{x}\)</span> is a scalar multiple of <span class="math inline">\(\mathbf{x}\)</span>, i.e., if <span class="math display">\[A\mathbf{x} = \lambda \mathbf{x}\]</span> <span class="math inline">\(\lambda\)</span> is called the eigenvalue of <span class="math inline">\(A\)</span> and <span class="math inline">\(\textbf{x}\)</span> is the eigenvector corresponding to <span class="math inline">\(\lambda\)</span>.</p>
<p>Example: <span class="math inline">\(\mathbf{x} = \begin{bmatrix}1\\2\end{bmatrix}\)</span> is an eigenvector of <span class="math inline">\(A = \begin{pmatrix}3 &amp; 0 \\ 8 &amp; -1\end{pmatrix}\)</span> corresponding to the eigenvalue <span class="math inline">\(\lambda = 3\)</span> since <span class="math display">\[\begin{pmatrix}3 &amp; 0 \\ 8 &amp; -1\end{pmatrix}\begin{bmatrix}1\\2\end{bmatrix} = \begin{bmatrix}3\\6\end{bmatrix} = 3 \mathbf{x}\]</span></p>
<p><strong>To find eigenvalues</strong>: <span class="math display">\[\begin{align}
  A\mathbf{x} &amp; = \lambda \mathbf{x} \\
  A\mathbf{x} &amp; = \lambda I \mathbf{x} \\
 (\lambda I - A ) \mathbf{x} &amp; =  0
 \end{align}\]</span></p>
<p>This will have a non-zero solution iff <span class="math inline">\(\det(\lambda I - A ) = 0\)</span> (characteristic equation). The scalars satisfying this equation are the eigenvalues of <span class="math inline">\(A\)</span>. The eigenvectors are then found by solving <span class="math inline">\((\lambda I - A ) \mathbf{x} = 0\)</span></p>
<p><strong>Example</strong>: Find the eigenvalues of <span class="math inline">\(A = \begin{pmatrix}1 &amp; 0 \\ 6 &amp; -1\end{pmatrix}\)</span></p>
<p><span class="math display">\[\begin{align}
 \lambda I - A  &amp; =  \lambda \begin{pmatrix}1 &amp; 0 \\ 0 &amp; 1\end{pmatrix} - \begin{pmatrix}1 &amp; 0 \\ 6 &amp; -1\end{pmatrix} \\
                &amp; = \begin{pmatrix}\lambda - 1 &amp; 0 \\ -6 &amp; \lambda + 1\end{pmatrix} \\
\det(\lambda I - A) &amp; = (\lambda - 1) (\lambda + 1) - (0)(-6)\\
                  &amp; = \lambda ^2 -1 \text{  (a.k.a. characteristic polynomial)}
  \end{align}\]</span> The solutions to <span class="math inline">\(\det(\lambda I - A)\)</span> are <span class="math inline">\(\lambda=1\)</span> and <span class="math inline">\(\lambda=-1\)</span></p>
<p>However, recall pythagorean solution to quadratic equation <span class="math inline">\(ax^2 + bx + c\)</span> is <span class="math display">\[x = \frac{-b \pm \sqrt{b^2-4ac}}{2a}\]</span></p>
<p><strong>To find eigenvectors</strong>: <span class="math display">\[\begin{align}
 (\lambda I - A ) \mathbf{x} &amp; =  0 \\
 \begin{pmatrix}\lambda - 1 &amp; 0 \\ -6 &amp; \lambda + 1\end{pmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix} &amp; = \begin{bmatrix}0\\0\end{bmatrix}\\
 \text{with $\lambda = 1$, } \begin{pmatrix}0 &amp; 0 \\ -6 &amp; 2\end{pmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix} &amp; = \begin{bmatrix}0\\0\end{bmatrix}\\
  \text{with $\lambda = -1$, } \begin{pmatrix}-2 &amp; 0 \\ -6 &amp; 0\end{pmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix} &amp; = \begin{bmatrix}0\\0\end{bmatrix}
  \end{align}\]</span></p>
<p>For <span class="math inline">\(\lambda=1\)</span>, <span class="math display">\[\begin{align}
  -6x_1 + 2x_2 &amp;= 0 \\
  3x_1 &amp; = x_2 \\
  x_1 &amp;= x_2/3
  \end{align}\]</span> If <span class="math inline">\(x_2=t\)</span> then <span class="math inline">\(\begin{bmatrix} 1/3 \\ 1\end{bmatrix}\)</span> is an eigenvector</p>
<p>For <span class="math inline">\(\lambda=-1\)</span>, <span class="math display">\[\begin{align}
  -2x_1  &amp;= 0 \\
  -6x_1 &amp; = 0 
  \end{align}\]</span> If <span class="math inline">\(x_2=t\)</span> then <span class="math inline">\(\begin{bmatrix} 0 \\ 1\end{bmatrix}\)</span> is an eigenvector</p>
<p><strong>Diagonalisation</strong></p>
<ul>
<li>An <span class="math inline">\(n \text{x} n\)</span> matrix <span class="math inline">\(A\)</span> is diagonisable <span class="math inline">\(\leftrightarrow\)</span> <span class="math inline">\(A\)</span> has n linear independent eigenvectors.<br />
</li>
<li>Solution to diagonalise <span class="math inline">\(A\)</span>:
<ul>
<li>Find <span class="math inline">\(n\)</span> linear independent eigenvectors of <span class="math inline">\(A\)</span>, <span class="math inline">\(\mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n\)</span></li>
<li>Form the matrix <span class="math inline">\(P\)</span> having <span class="math inline">\(\mathbf{p}_1, \mathbf{p}_2, \dots, \mathbf{p}_n\)</span> as its column vectors</li>
<li><span class="math inline">\(P^{-1}AP\)</span> will be diagonal with <span class="math inline">\(\lambda_1, \lambda_2, \ldots, \lambda_n\)</span> as successive diagonal entries, where <span class="math inline">\(\lambda_i\)</span> is the eigenvalue corresponding to <span class="math inline">\(\mathbf{p}_i\)</span></li>
</ul></li>
</ul>
<p>Example: <span class="math display">\[\begin{align}
P &amp; = \begin{pmatrix}1/3 &amp; 0 \\ 1 &amp; 1\end{pmatrix} \\
P^{-1} &amp;= 3 \begin{pmatrix}1 &amp; 0 \\ -1 &amp; 1/3\end{pmatrix} \\
  &amp; = \begin{pmatrix}3 &amp; 0 \\ -3 &amp; 1\end{pmatrix} \\
P^{-1}AP &amp;=  \begin{pmatrix}3 &amp; 0 \\ -3 &amp; 1\end{pmatrix}\begin{pmatrix}1 &amp; 0 \\ 6 &amp; -1\end{pmatrix}\begin{pmatrix}1/3 &amp; 0 \\ 1 &amp; 1\end{pmatrix}\\
 &amp;= \begin{pmatrix}3 &amp; 0 \\ 3 &amp; 11\end{pmatrix}\begin{pmatrix}1/3 &amp; 0 \\ 1 &amp; 1\end{pmatrix}\\
 &amp;= \begin{pmatrix}1 &amp; 0 \\ 0 &amp; -1\end{pmatrix} \\
 &amp;=\begin{pmatrix}\lambda_1  &amp; 0 \\ 0 &amp; \lambda_2\end{pmatrix}
\end{align}\]</span></p>
<p><strong>Orthogonal Diagonalisation</strong> If <span class="math inline">\(A\)</span> is a symmetric matrix, then eigenvectors from different eigenspaces are orthogonal; to orthogonally diagonslize a symmetrix matrix:</p>
<ol style="list-style-type: decimal">
<li>Find a basis for each eigenspace of A</li>
<li>Apply the Gram-Schmidt process (pp192-194, Anton) to each of these bases to obtain an orthonormal basis for each eigenspace</li>
<li>Form the matrix <span class="math inline">\(P\)</span>, whose columns are the basis vectors contructed in hte previous step; this matrix orthogonally diagonalises <span class="math inline">\(A\)</span>.</li>
</ol>
</div>
